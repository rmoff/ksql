---
version: '2'
services:
  zookeeper:
    ports:
      - 2181:2181
    image: confluentinc/cp-zookeeper:5.0.0
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000

  kafka:
    image: confluentinc/cp-enterprise-kafka:5.0.0
    depends_on:
      - zookeeper
    #ports:
    # This would expose 9092 for external connections to the broker
    # Use kafka:29092 for connections internal on the docker network
    # See https://rmoff.net/2018/08/02/kafka-listeners-explained/ for details
    #  - 9092:9092
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_METRIC_REPORTERS: io.confluent.metrics.reporter.ConfluentMetricsReporter
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 100
      CONFLUENT_METRICS_REPORTER_BOOTSTRAP_SERVERS: kafka:29092
      CONFLUENT_METRICS_REPORTER_ZOOKEEPER_CONNECT: zookeeper:2181
      CONFLUENT_METRICS_REPORTER_TOPIC_REPLICAS: 1
      CONFLUENT_METRICS_ENABLE: 'true'
      CONFLUENT_SUPPORT_CUSTOMER_ID: 'anonymous'

  schema-registry:
    image: confluentinc/cp-schema-registry:5.0.0
    depends_on:
      - zookeeper
      - kafka
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_KAFKASTORE_CONNECTION_URL: zookeeper:2181

  kafka-connect:
    image: confluentinc/cp-kafka-connect:5.0.0
    ports:
      - 8083:8083
    depends_on:
      - zookeeper
      - kafka
      - schema-registry
    environment:
      CONNECT_BOOTSTRAP_SERVERS: "kafka:29092"
      CONNECT_REST_PORT: 8083
      CONNECT_GROUP_ID: compose-connect-group
      CONNECT_CONFIG_STORAGE_TOPIC: docker-connect-configs
      CONNECT_OFFSET_STORAGE_TOPIC: docker-connect-offsets
      CONNECT_STATUS_STORAGE_TOPIC: docker-connect-status
      CONNECT_KEY_CONVERTER: io.confluent.connect.avro.AvroConverter
      CONNECT_KEY_CONVERTER_SCHEMA_REGISTRY_URL: 'http://schema-registry:8081'
      CONNECT_VALUE_CONVERTER: io.confluent.connect.avro.AvroConverter
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: 'http://schema-registry:8081'
      CONNECT_INTERNAL_KEY_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_INTERNAL_VALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_REST_ADVERTISED_HOST_NAME: "kafka-connect"
      CONNECT_LOG4J_ROOT_LOGLEVEL: "INFO"
      CONNECT_LOG4J_LOGGERS: "org.apache.kafka.connect.runtime.rest=WARN,org.reflections=ERROR"
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: "1"
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: "1"
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: "1"
      CONNECT_PLUGIN_PATH: '/usr/share/java'
      CLASSPATH: /usr/share/java/monitoring-interceptors/monitoring-interceptors-5.0.0.jar
      CONNECT_PRODUCER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor"
      CONNECT_CONSUMER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor"
    volumes:
     - $PWD/demo:/scripts
     - $PWD/demo/connect-config:/usr/share/java/null-smt
    command: "bash -c '/etc/confluent/docker/run & \
                       /scripts/ksql-tables-to-grafana.sh && \
                       sleep infinity'"

  ksql-server:
    image: confluentinc/cp-ksql-server:5.0.0
    ports:
      - 8088:8088
    depends_on:
      - kafka
      - schema-registry
      - datagen-clickstream
    environment:
      KSQL_CUB_KAFKA_TIMEOUT: 300
      KSQL_BOOTSTRAP_SERVERS: kafka:29092
      KSQL_LISTENERS: http://0.0.0.0:8088
      KSQL_KSQL_SCHEMA_REGISTRY_URL: http://schema-registry:8081
      KSQL_KSQL_SERVICE_ID: confluent_rmoff_01
      KSQL_PRODUCER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor"
      KSQL_CONSUMER_INTERCEPTOR_CLASSES: "io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor"
      KSQL_KSQL_QUERIES_FILE: /scripts/clickstream-schema.sql
      KSQL_KSQL_COMMIT_INTERVAL_MS: 2000
      KSQL_KSQL_CACHE_MAX_BYTES_BUFFERING: 10000000
      KSQL_KSQL_AUTO_OFFSET_RESET: earliest
    volumes:
     - $PWD/demo:/scripts

  control-center:
    image: confluentinc/cp-enterprise-control-center:5.0.0
    depends_on:
      - zookeeper
      - kafka
      - schema-registry
      - kafka-connect
      - ksql-server
    ports:
      - "9021:9021"
    environment:
      CONTROL_CENTER_BOOTSTRAP_SERVERS: 'kafka:29092'
      CONTROL_CENTER_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      CONTROL_CENTER_CONNECT_CLUSTER: 'kafka-connect:8083'
      CONTROL_CENTER_KSQL_URL: "http://ksql-server:8088"
      CONTROL_CENTER_CONNECT_CLUSTER: "http://kafka-connect:8083"
      CONTROL_CENTER_KSQL_ADVERTISED_URL: "http://localhost:8088"
      CONTROL_CENTER_SCHEMA_REGISTRY_URL: "https://schema-registry:8081"
      CONTROL_CENTER_REPLICATION_FACTOR: 1
      CONTROL_CENTER_INTERNAL_TOPICS_PARTITIONS: 1
      CONTROL_CENTER_MONITORING_INTERCEPTOR_TOPIC_PARTITIONS: 1
      CONFLUENT_METRICS_TOPIC_REPLICATION: 1
      CONTROL_CENTER_CUB_KAFKA_TIMEOUT: 300
      PORT: 9021

  # Runs the Kafka KSQL data generator for ratings - continuous
  datagen-clickstream:
    image: confluentinc/ksql-examples:5.0.0
    depends_on:
      - kafka
      - schema-registry
    command: "bash -c 'echo Waiting for Kafka to be ready... && \
                       cub kafka-ready -b kafka:29092 1 300 && \
                       ksql-datagen \
                          quickstart=clickstream \
                          format=json \
                          topic=clickstream \
                          maxInterval=100 \
                          bootstrap-server=kafka:29092'"

  # Runs the Kafka KSQL data generator for codes - exits once done
  datagen-codes:
    image: confluentinc/ksql-examples:5.0.0
    depends_on:
      - kafka
      - schema-registry
    command: "bash -c 'echo Waiting for Kafka to be ready... && \
                       cub kafka-ready -b kafka:29092 1 300 && \
                       echo interceptor.classes=io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor > /datagen.properties && \
                       ksql-datagen \
                          bootstrap-server=kafka:29092 \
                          quickstart=clickstream_codes \
                          format=json \
                          topic=clickstream_codes \
                          maxInterval=20 \
                          iterations=100 \
                          propertiesFile=/datagen.properties'"
    # needs monitoring interceptors JAR to be in the image, which I can't find. 
    # command: "bash -c 'echo Waiting for Kafka to be ready... && \
    #                    cub kafka-ready -b kafka:29092 1 300 && \
    #                    echo interceptor.classes=io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor > /datagen.properties && \
    #                    ksql-datagen \
    #                       bootstrap-server=kafka:29092 \
    #                       quickstart=clickstream_codes \
    #                       format=json \
    #                       topic=clickstream_codes \
    #                       maxInterval=20 \
    #                       iterations=100 \
    #                       propertiesFile=/datagen.properties'"

  # Runs the Kafka KSQL data generator for users - continuous
  datagen-users:
    image: confluentinc/ksql-examples:5.0.0
    depends_on:
      - kafka
      - schema-registry
    command: "bash -c 'echo Waiting for Kafka to be ready... && \
                       cub kafka-ready -b kafka:29092 1 300 && \
                       ksql-datagen \
                          bootstrap-server=kafka:29092 \
                          quickstart=clickstream_users \
                          format=json \
                          topic=clickstream_users \
                          maxInterval=10 \
                          iterations=1000'"

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:6.3.0
    ports:
      - 9200:9200
    environment:
      xpack.security.enabled: "false"
      ES_JAVA_OPTS: "-Xms1g -Xmx1g"
    volumes:
     - $PWD/demo:/scripts
    command: "bash -c '/usr/local/bin/docker-entrypoint.sh & \
                       /scripts/elastic-dynamic-template.sh && \
                       sleep infinity'"

  grafana:
    image: grafana/grafana:5.2.4
    ports:
      - 3000:3000
    volumes:
     - $PWD/demo:/scripts
    entrypoint: "bash -c '/scripts/clickstream-analysis-dashboard.sh && \
                       sleep infinity & \
                       /run.sh'"

# Kibana's useful for exploring the data, and/or dev tools for
# Elasticsearch. It's not core to the demo though, so not enabled
# by default. 
  # kibana:
  #   image: docker.elastic.co/kibana/kibana:6.3.0
  #   depends_on:
  #     - elasticsearch
  #   ports:
  #     - 5601:5601
  #   environment:
  #     xpack.security.enabled: "false"
  #     discovery.type: "single-node"

#docker-compose exec kafka-connect bash -c '

